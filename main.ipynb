{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "from src.preprocessing.dataset import get_datasets\n",
    "from src.preprocessing.tokenizer_vocab import tokenize_data, build_vocab, numericalize_data, set_data_format\n",
    "from src.preprocessing.dataloader import get_data_loader\n",
    "\n",
    "from src.model.seq2vid import Encoder, Decoder, Vid2Seq\n",
    "from src.model.lightning import LightVid2Seq\n",
    "\n",
    "from src.constants import (\n",
    "    VIDEO_IDS,\n",
    "    SENTENCE,\n",
    "    SENTENCE_IDS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "SEED = 42\n",
    "\n",
    "# random.seed(seed)\n",
    "# torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed(seed)\n",
    "# torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DATA_DIR = \"./data\"\n",
    "\n",
    "FILE_PATHS = {\n",
    "    \"train\": f\"{DATA_DIR}/how2sign/how2sign_realigned_train.csv\",\n",
    "    \"val\": f\"{DATA_DIR}/how2sign/how2sign_realigned_val.csv\",\n",
    "    \"test\": f\"{DATA_DIR}/how2sign/how2sign_realigned_test.csv\",\n",
    "}\n",
    "\n",
    "VIDEO_DIRS = {\n",
    "    \"train\": f\"{DATA_DIR}/how2sign/train/compressed_videos\",\n",
    "    \"val\": f\"{DATA_DIR}/how2sign/val/compressed_videos\",\n",
    "    \"test\": f\"{DATA_DIR}/how2sign/test/compressed_videos\",\n",
    "}\n",
    "\n",
    "TRAIN_SIZES = {\n",
    "    \"train\": 0.00228,  # 70 samples\n",
    "    \"val\": 0.0088,     # 15 samples\n",
    "    \"test\": 0.0067,    # 15 samples\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dict = get_datasets(FILE_PATHS, VIDEO_DIRS, TRAIN_SIZES, SEED)\n",
    "\n",
    "train_data = datasets_dict[\"train\"]\n",
    "test_data = datasets_dict[\"test\"]\n",
    "val_data = datasets_dict[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_LENGTH = 1_000\n",
    "IS_LOWER = True\n",
    "SOS_TOKEN = \"<sos>\"\n",
    "EOS_TOKEN = \"<eos>\"\n",
    "UNK_TOKEN = \"<unk>\"\n",
    "PAD_TOKEN = \"<pad>\"\n",
    "MIN_FREQ = 1\n",
    "\n",
    "SPECIAL_TOKENS = [UNK_TOKEN, PAD_TOKEN, SOS_TOKEN, EOS_TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb43be0d98d4fccb6becbe0aa786648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdf7aa3e5e0495fbed8489846023ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5001afa4cd444d8a2e37302b9f4e225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7338f4507a034a21bf4c46d4a1c8530b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/70 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f061e0b556ba4574ad0ab9ad3050db6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf060559a8ac4979b74bc3f57ce2196d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the spaCy model\n",
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "train_data = tokenize_data(train_data, en_nlp, MAX_LENGTH, IS_LOWER, SOS_TOKEN, EOS_TOKEN)\n",
    "test_data = tokenize_data(test_data, en_nlp, MAX_LENGTH, IS_LOWER, SOS_TOKEN, EOS_TOKEN)\n",
    "val_data = tokenize_data(val_data, en_nlp, MAX_LENGTH, IS_LOWER, SOS_TOKEN, EOS_TOKEN)\n",
    "\n",
    "\n",
    "# Build the vocabulary\n",
    "vocab = build_vocab(train_data, SPECIAL_TOKENS, MIN_FREQ)\n",
    "\n",
    "# Assert that special tokens are correctly indexed\n",
    "assert vocab[UNK_TOKEN] == 0\n",
    "assert vocab[PAD_TOKEN] == 1\n",
    "\n",
    "# Set the default index for unknown tokens\n",
    "vocab.set_default_index(vocab[UNK_TOKEN])\n",
    "\n",
    "train_data = numericalize_data(train_data, vocab)\n",
    "test_data = numericalize_data(test_data, vocab)\n",
    "val_data = numericalize_data(val_data, vocab)\n",
    "\n",
    "train_data = set_data_format(train_data)\n",
    "test_data = set_data_format(test_data)\n",
    "val_data = set_data_format(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "pad_index = vocab[PAD_TOKEN]\n",
    "sampling_rate = 10\n",
    "\n",
    "train_data_loader = get_data_loader(train_data, BATCH_SIZE, pad_index, VIDEO_DIRS[\"train\"], sampling_rate, shuffle=True, num_worker=2)\n",
    "test_data_loader = get_data_loader(test_data, BATCH_SIZE, pad_index, VIDEO_DIRS[\"test\"], sampling_rate, shuffle=True, num_worker=2)\n",
    "val_data_loader = get_data_loader(val_data, BATCH_SIZE, pad_index, VIDEO_DIRS[\"val\"], sampling_rate, shuffle=True, num_worker=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 10\n",
    "assert input_dim == sampling_rate\n",
    "output_dim = len(vocab)\n",
    "decoder_embedding_dim = 64\n",
    "hidden_dim = 64\n",
    "n_lstm_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_dim,\n",
    "    hidden_dim,\n",
    "    n_lstm_layers,\n",
    "    encoder_dropout,\n",
    ")\n",
    "\n",
    "decoder = Decoder(\n",
    "    output_dim,\n",
    "    decoder_embedding_dim,\n",
    "    hidden_dim,\n",
    "    n_lstm_layers,\n",
    "    decoder_dropout,\n",
    ")\n",
    "\n",
    "pad_index = pad_index\n",
    "teacher_forcing_ratio = 0.9\n",
    "clip = 1.0\n",
    "\n",
    "model = LightVid2Seq(encoder, decoder, pad_index, teacher_forcing_ratio, clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m: nn.Module):\n",
    "    for _, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "\n",
    "model = model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = L.Trainer(max_epochs=1, log_every_n_steps=1, default_root_dir=\"./weight\")\n",
    "\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "if best_model_path == \"\":\n",
    "    best_model_path = None\n",
    "\n",
    "# trainer.fit(model, train_data_loader, val_data_loader, ckpt_path=best_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "The first thing to do is to test the model's performance on the test set.\n",
    "\n",
    "We'll load the parameters (`state_dict`) that gave our model the best validation loss and run it on the test set to get our test loss and perplexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "require path to best model",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path_to_best_checkpoint \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mcheckpoint_callback\u001b[38;5;241m.\u001b[39mbest_model_path\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m path_to_best_checkpoint \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequire path to best model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m test_loss \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtest(model, test_data_loader, ckpt_path\u001b[38;5;241m=\u001b[39mpath_to_best_checkpoint)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m| Test Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test PPL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mexp(test_loss)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m7.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m |\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: require path to best model"
     ]
    }
   ],
   "source": [
    "path_to_best_checkpoint = trainer.checkpoint_callback.best_model_path\n",
    "assert path_to_best_checkpoint != \"\", \"require path to best model\"\n",
    "\n",
    "test_loss = trainer.test(model, test_data_loader, ckpt_path=path_to_best_checkpoint)[0][\"test_loss\"]\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: It's giving an error because of the new changes.\n",
    "\n",
    "# def translate_video(\n",
    "#     video,\n",
    "#     encoder: Encoder,\n",
    "#     decoder: Decoder,\n",
    "#     vocab,\n",
    "#     sos_token,\n",
    "#     eos_token,\n",
    "#     device,\n",
    "#     max_output_length=25,\n",
    "# ):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         hidden, cell = encoder(video)\n",
    "#         print(hidden.size(), cell.size())\n",
    "#         inputs = vocab.lookup_indices([sos_token])\n",
    "#         for _ in range(max_output_length):\n",
    "#             inputs_tensor = torch.LongTensor([inputs[-1]])#.to(device)\n",
    "#             output, hidden, cell = decoder(inputs_tensor, hidden[0], cell[0])\n",
    "#             predicted_token = output.argmax(-1).item()\n",
    "#             inputs.append(predicted_token)\n",
    "#             if predicted_token == vocab[eos_token]:\n",
    "#                 break\n",
    "#         tokens = vocab.lookup_tokens(inputs)\n",
    "#     return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_video(\n",
    "    batch_video,\n",
    "    model: Vid2Seq,\n",
    "    vocab,\n",
    "    sos_token,\n",
    "    eos_token,\n",
    "    device=\"cpu\",\n",
    "    max_output_length=25,\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch_size = batch_video.size(1)\n",
    "        # trg = torch.LongTensor(max_output_length, batch_size)\n",
    "        trg = torch.zeros((max_output_length, batch_size), dtype=torch.long, device=device)\n",
    "        trg = torch.full_like(trg, vocab[sos_token])\n",
    "        \n",
    "        output = model(batch_video, trg, 0)\n",
    "        output_ids = output.argmax(-1)\n",
    "\n",
    "        tokens = [vocab.lookup_tokens(output_ids[:, i].tolist()) for i in range(batch_size)]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 15, 10, 3, 224, 224]), torch.Size([55, 15]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(test_data_loader))\n",
    "batch_size = batch[VIDEO_IDS].size(1)\n",
    "\n",
    "expected_translation = [vocab.lookup_tokens(batch[SENTENCE_IDS][:, i].tolist()) for i in range(batch_size)]\n",
    "\n",
    "batch[VIDEO_IDS].size(), batch[SENTENCE_IDS].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate_video(\n",
    "    batch[VIDEO_IDS],\n",
    "    model.model,\n",
    "    vocab,\n",
    "    SOS_TOKEN,\n",
    "    EOS_TOKEN,\n",
    "    # device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,\n",
       " [['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants'],\n",
       "  ['chest',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants',\n",
       "   'antioxidants']])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(translation), translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "zeros() received an invalid combination of arguments - got (tuple, device=str, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m translations \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtranslate_video\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[43mVIDEO_IDS\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#.to(device),\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43men_nlp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mSOS_TOKEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mEOS_TOKEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(train_data_loader) \u001b[38;5;66;03m### raplace with test_data_loader\u001b[39;00m\n\u001b[1;32m     12\u001b[0m ]\n",
      "Cell \u001b[0;32mIn[43], line 14\u001b[0m, in \u001b[0;36mtranslate_video\u001b[0;34m(batch_video, model, vocab, sos_token, eos_token, device, max_output_length)\u001b[0m\n\u001b[1;32m     12\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m batch_video\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# trg = torch.LongTensor(max_output_length, batch_size)\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m trg \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_output_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m trg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull_like(trg, vocab[sos_token])\n\u001b[1;32m     17\u001b[0m output \u001b[38;5;241m=\u001b[39m model(batch_video, trg, \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: zeros() received an invalid combination of arguments - got (tuple, device=str, dtype=torch.dtype), but expected one of:\n * (tuple of ints size, *, tuple of names names, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n * (tuple of ints size, *, Tensor out, torch.dtype dtype, torch.layout layout, torch.device device, bool pin_memory, bool requires_grad)\n"
     ]
    }
   ],
   "source": [
    "translations = [\n",
    "    translate_video(\n",
    "        example[VIDEO_IDS],#.to(device),\n",
    "        model,\n",
    "        en_nlp,\n",
    "        vocab,\n",
    "        SOS_TOKEN,\n",
    "        EOS_TOKEN,\n",
    "        device,\n",
    "    )\n",
    "    for example in tqdm.tqdm(train_data_loader) ### raplace with test_data_loader\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'translations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, translate \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtranslations\u001b[49m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(translate)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m<\u001b[39m i:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'translations' is not defined"
     ]
    }
   ],
   "source": [
    "for i, translate in enumerate(translations):\n",
    "    print(translate)\n",
    "    if 5 < i:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('now now the , , , , , , , , , , , , , , , , , , , ,',\n",
       " [\"You also want to be sure that you have very comfortable socks because you're on your feet a lot.\"])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = [\" \".join(translation[1:-1]) for translation in translations]\n",
    "\n",
    "references = [[example[\"en\"]] for example in train_data] ### raplace with test_data\n",
    "\n",
    "predictions[0], references[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer_fn(nlp, lower):\n",
    "    def tokenizer_fn(s):\n",
    "        tokens = [token.text for token in nlp.tokenizer(s)]\n",
    "        if lower:\n",
    "            tokens = [token.lower() for token in tokens]\n",
    "        return tokens\n",
    "\n",
    "    return tokenizer_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_fn = get_tokenizer_fn(en_nlp, lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['now', 'now', 'the', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',', ',']\n",
      "['you', 'also', 'want', 'to', 'be', 'sure', 'that', 'you', 'have', 'very', 'comfortable', 'socks', 'because', 'you', \"'re\", 'on', 'your', 'feet', 'a', 'lot', '.']\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    tokenizer_fn(predictions[0]),\n",
    "    tokenizer_fn(references[0][0]),\n",
    "    sep=\"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bleu.compute(\n",
    "    predictions=predictions, references=references, tokenizer=tokenizer_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0,\n",
       " 'precisions': [0.07080745341614907, 0.0, 0.0, 0.0],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.0274409700063816,\n",
       " 'translation_length': 1610,\n",
       " 'reference_length': 1567}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
